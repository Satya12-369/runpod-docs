{
    "content": "Serverless\nEndpoints\nGet started\nOn this page\nGet started\nNow that your Endpoint is deployed, send a test. This is a great way to test your Endpoint before\nsending a request from your application.\nSend a Request\n1. From the Endpoint's page, select Requests.\n2. Choose Run.\n3. You should see a successful response with the following:\nAfter a few minutes, the stream will show the full response.\nYou can now begin sending requests to your Endpoint from your terminal and an application.\nSend a request using cURL\nOnce your Endpoint is deployed, you can send a request. This example sends a response to the\nEndpoint using cURL; however, you can use any HTTP client.\n{\n  \"id\": \"6de99fd1-4474-4565-9243-694ffeb65218-u1\",\n  \"status\": \"IN_QUEUE\"\n}\ncurl --request POST \\\n     --url https://api.runpod.ai/v2/${YOUR_ENDPOINT}/runsync \n     --header \"accept: application/json\" \\\n     --header \"authorization: ${YOUR_API_KEY}\" \\\n     --header \"content-type: application/json\" \\\n     --data '\n{\nAsk AI\nAsk AI\nRunPod\nWhere YOUR_ENDPOINT  is the name of your Endpoint and YOUR_API_KEY  is your API Key.\nNOTE\nDepending on any modi\ufb01cations you made to your Handler Function, you may need to\nmodify the request.\nNext steps\nNow that you have successfully launched an endpoint using our template, you can:\nSend requests to the Endpoint\nIf the models provided aren't enough, you can write your own customize Function Handler:\nCustomize the Handler Function\nEdit this page\nPrevious\n\u00ab Overview\nNext\nSend a request \u00bb\nDocs\nOverview\n  \"input\": {\n    \"prompt\": \"A coffee cup.\",\n    \"height\": 512,\n    \"width\": 512,\n    \"num_outputs\": 1,\n    \"num_inference_steps\": 50,\n    \"guidance_scale\": 7.5,\n    \"scheduler\": \"KLMS\"\n  }\n}\n'\nAsk AI\nAsk AI\nTutorials\nAI APIs\nCommunity\nDiscord\nContact us\nMore\nBlog\nGitHub\nCopyright \u00a9 2024 RunPod\nAsk AI\nAsk AI\n"
}