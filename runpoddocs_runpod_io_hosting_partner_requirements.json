{
    "content": "Hosting\nRequirements\nOn this page\nRequirements\nSoftware Speci\ufb01cations\nUbuntu Server 22.04 LTS:\nBasic Linux pro\ufb01ciency.\nAbility to remotely connect via SSH.\nMinimal Secure Cloud Speci\ufb01cations\nLatest NVIDIA GPUs, at least 30xx or RTX A4000 or higher.\nOption 1: At least 20 GPUs in total, each with a minimum of 12 GB VRAM.\nOption 2: At least 8 GPUs in total, each with a minimum of 80 GB of VRAM.\nPCIE 3.0 x16/PCIE 4.0 x8 per GPU or faster. PCIe 4.0 x16 recommended.\nDemand is highest for SXM 80GB, PCI 80GB, 4090 24GB and L40 or Ada A6000 48GB\nmodels. We also require 2 GPU per server at minimum for best rental rates. 8x\ncon\ufb01gurations are the most popular.\nMinimum of 4 Physical CPU Cores Per GPU + 2 for system operations. Prioritize as fast as\npossible CPU core clock over more cores. For example, a 24 cores CPU clocking at 5.0 GHz\nis preferred to a 128 cores CPU clocking at 3.0 GHz for a 4 GPU con\ufb01guration.\nYour RAM should at minimum equals your total vRAM of all GPUs + 12GB for system\noperations.\n1 TB+ of RAM recommended for 8x 80GB vRAM GPU con\ufb01gurations.\nWe want an absolute minimum of 1TB+ of NVME space per GPU for each server, ideally\n2TB+ (excluding the OS drives). For larger GPU like 80GB, 4TB per GPU is recommended.\nAt least 3,000 MB/s read/write speed is required.\nWe recommend 2 smaller NVME disk in RAID 1 for the operating system (2x 500GB is\n\ufb01ne).\nFor data drives, it can be any number of those, but make sure the total is at least 1-\n2TB+ per GPU. If several data drives are provided, you need to create a LVM volume for\nthose.\nAsk AI\nAsk AI\nRunPod\n10gbps Bidirectional Internet Speed as backbone, and minimum of 1gbps symetrical per\nserver.\nStatic Public IP.\nA single IP can be shared between multiple servers.\nAccess and ability to port forwarding. At least 30 ports forwarded per GPU per server.\nAbide by Tier III+ Datacenter Standards.\nRobust Uninterruptible Power Supply and backup generator.\nInternet Service Provider redundancy.\n24/7 on-site security and technical staff.\n400+ GPU Capacity.\n40GB/s Interconnect between servers.\nAbility to deploy network storage cluster.\nMost importantly: the ability to scale GPU supply over time.\nPCIe Risers\nIf your system uses PCIe risers, they must have redriver functionality.\nEdit this page\nPrevious\n\u00ab Maintenance and reliability\nNext\nTroubleshooting \u00bb\nDocs\nOverview\nTutorials\nAI APIs\nCommunity\nDiscord\nContact us\nAsk AI\nAsk AI\nMore\nBlog\nGitHub\nCopyright \u00a9 2024 RunPod\nAsk AI\nAsk AI\n"
}