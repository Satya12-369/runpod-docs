{
    "content": "Serverless\nEndpoints\nSend a request\nOn this page\nSend a request\nWith a successful custom endpoint deployed, you are nearly ready to make a job request. Let's\nstart by constructing our request body that will be submitted.\nJSON Request Body\nRequests to your endpoint must be made via a JSON formatted request; at a minimum, it will\nneed to have an input  key containing a dictionary of inputs required to complete your job\nrequest. For example, if your handler required an input prompt, you might send in something like\nthis:\nOptional Inputs\nAlong with an input key, other top-level inputs can also be included and offer different functions.\nIf a key is passed in at the top level and not included here, it will be discarded and unavailable to\nyour handler.\n\ud83d\udc4d These optional inputs are available to all endpoints regardless of the worker.\n\u2693 | Webhook\nTo be noti\ufb01ed of completed jobs, a URL can be passed within the top level of the request like so:\n{\n  \"input\": {\n    \"prompt\": \"The lazy brown fox jumps over the\"\n  }\n}\nAsk AI\nAsk AI\nRunPod\nYour webhook endpoint should respond with a 200 status to acknowledge the successful call. If\nnot received, the webhook will be attempted up to 2 times after a 10-second timeout.\nA POST request will be sent to your URL when the job is complete. This request will contain the\nsame information you would receive if you fetched the results from the /status/{job_id}\nendpoint.\n\ud83d\udcdc | Execution Policy\nBy default, if a job remains IN_PROGRESS  for longer than 24 hours, the worker that has that job\nwill be terminated. If you know the upper limit (with some margin) on how long a job should take,\nyou can prevent stale or dead workers from running excessively by setting the execution timeout\npolicy.\nSetting this policy will limit how long a worker remains IN_PROGRESS  before the worker is\nkilled.\nMinimum: 5000ms\nDefault: 86400000ms (24 hours)\n\ud83d\udcbe | S3-Compatible Storage\nThe credentials for S3-compatible object storage can be passed in with the request as follows:\n{\n  \"input\": {},\n  \"webhook\": \"https://URL.TO.YOUR.WEBHOOK\"\n}\n{\n  \"input\": {},\n \n\"policy\":{\n     \n\"executionTimeout\": int # time in milliseconds\n   \n}\n}\n{\n  \"input\": {},\n  \"s3Config\": {\n    \"accessId\": \"key_id_or_username\",\nAsk AI\nAsk AI\nThe con\ufb01guration is only passed onto the worker; it will not be returned as part of the job request\noutput.\nNote: The serverless worker will need to contain the logic/functionality that allows it to make sure\nof this input. If you build a custom endpoint and request s3Con\ufb01g in the input, your worker is\nultimately responsible for using the information passed in to upload the output.\nEdit this page\nPrevious\n\u00ab Get started\nNext\nManage Endpoints \u00bb\nDocs\nOverview\nTutorials\nAI APIs\nCommunity\nDiscord\nContact us\nMore\nBlog\nGitHub\n    \"accessSecret\": \"key_secret_or_password\",\n    \"bucketName\": \"storage_location_name\",\n    \"endpointUrl\": \"storage_location_address\"\n  }\n}\nAsk AI\nAsk AI\nCopyright \u00a9 2024 RunPod\nAsk AI\nAsk AI\n"
}